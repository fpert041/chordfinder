For this Assignment I set out to analyse music by retrieving harmonic components and identifying tonal features of music.

I studied verius approaches and eventually settled on working with audio.

Working with scores, in fact, poses the problem of not being able to analyse and potentially respond to pieces for which there isn't a fixed, comprehensive score. Furthermore, analysing scores in a way other than the trivial grouping of the "presently sounding" notes, would require at least a tonal analysis that would be hard to achieve without complex machine learning algorithms and a huge training dataset to make them work. (D.Cope - Computer Models of Musical Creativity 2005)

Working with audio has also the advantage of creating a tool which can be used out-of-the-box for live score following, improvisation and harmonisation in performaces.

It can then be expanded using machine learnig, but can work with a more rule-based approach using a chromatic analysis of FFT data (spectrum analysis using a chromagram re-binning)

Having worked extensively with the JS object in Max and having already made a piece that used externals for algorithmic composition, this time I wanted to explore the real-time audio realm of MSP

I initially tried with the pfft object that Max comes with, as well as with Gen.

The breaktrhough, though, arrived (perhaps a bit late) when I found out it was feasible to code an external (.mxo) in C++ rather than C.

I found material for Max 6 and updated it for Max 7, rewriting settings and files as I went along. The template is now public on my gitLab http://gitlab.doc.gold.ac.uk/fpert041/maxcpp

The biggest issue was to find a strong enough Algorithm that would work well when wapped up into a set of C++ classes for a Max object

I evaluated the various options and finally settled on the Adam Stark's one (his 2011 Thesis is included as a pdf in the "chord-detector" subfolder), using a very straightforward FFT library (it's called keep-it-simple-stupid so definitely straightforward and light). The KSS library does not have heavy compiled files which may have caused issues with the architecture and can be used by calling just a couple of functions from it clean headers.

The basic idea behind the algorithm consists of analysing the spectrum of audio signal using a Fast Fourier Transform and then re-binning the data to calcualte a 12-energy-bin chromagram. Once this is done, the program needs to compare this information with a series of chord profiles and find a match based on the similarity/difference of their chromatic features.  

All the components of the Algorithm chosen can be fairly "easily" hard-coded and programmed in just 2 cpp files (plus the library c files).

The most creative and fun part of all was testing the results and choosing appropriate values for bias or noise-floor variables. Incidentally, these very variables would be a good starting point for introducing machine learning and back-propagation flexible adjustment into the software.

Although at the moment I have mostly used my external "in the lab", I have built it with the idea of creating providing easy to use information for live harmonisation and melody generation (as well as to study the harmonic content of sound). This is particularly evident by the provision, within the outputs, of a straightforward numerical encoding for the chord components and its root note, as well as a list of the chord's characteristic midi notes. This data can be easily used to feed a scale-based arpeggiator, a notes-generator, a harmoniser and so forth.

see Readme.md for further info on how the object works

 

LINK TO DEMOSTRATION VIDEO: https://youtu.be/rSSXzX0vQe4



Francesco Perticarari